{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2a98d1-be96-4338-9fa2-047791d78a87",
   "metadata": {},
   "source": [
    "# Model Evaluator for Arthropod Detection\n",
    "\n",
    "This notebook evaluates a TensorFlow model trained to classify various arthropod species. It includes sections for loading the model, preparing the validation dataset, and calculating evaluation metrics, such as the confusion matrix and classification report, to assess model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44edf72-03a2-4176-827f-596235aad909",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import necessary libraries for model evaluation, image preprocessing, and visualization. Key libraries include TensorFlow for loading the model, `sklearn` for evaluation metrics, and `matplotlib` for visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9f420-f326-46e0-a001-7b1f009c309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from jupyterUtils import *\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a589496e-d3c1-41de-8584-1f5ef51a5757",
   "metadata": {},
   "source": [
    "## Load the Pre-Trained Model\n",
    "\n",
    "Load the trained model from the specified file path. Ensure that the model file path is correct and that it matches the model architecture and data used for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583e593-2540-4bf8-ba01-86c317cdac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = ProgressBar(message=\"Loading Model\")\n",
    "model_path   = '../models/10000_images_2_layers'\n",
    "model        = tf.keras.models.load_model(model_path)\n",
    "progress_bar.stop()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09fc6a-76fc-4251-9386-4122073a5458",
   "metadata": {},
   "source": [
    "## Predict a Single Image\n",
    "\n",
    "Choose an image to run through the model. The image will be rescaled, normalized, evaluated by the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdb8d6-48d3-4184-bcad-e1270a63b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"bee\", \"beetle\", \"moth\", \"spider\", \"wasp\"]\n",
    "image_path   = \"../data/images/wasp/wasp_4.jpg\"\n",
    "progress_bar.stop()\n",
    "progress_bar = ProgressBar(message=\"Classifying Image\")\n",
    "predict_image(model, image_path, class_names, 80)\n",
    "progress_bar.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207d1c0-9365-4a88-bad3-edeb6baf6429",
   "metadata": {},
   "source": [
    "## Load Validation Dataset\n",
    "\n",
    "Load and preprocess an entire validation dataset. This dataset will be used to evaluate the model's performance and provide insight into how well the model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe99bb7-f449-4f96-8823-9d4940629a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = ProgressBar(message=\"Creating Validaton Dataset\")\n",
    "\n",
    "validation_dataset = create_normalized_dataset(\n",
    "    dataset_dir      = '../data/images',\n",
    "    validation_split = 0.2,\n",
    "    subset           = \"validation\",\n",
    "    seed             = 123,\n",
    "    image_size       = (224, 224),\n",
    "    batch_size       = 32\n",
    ")\n",
    "progress_bar.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65c1e4-c4df-4ae9-ae85-e29ef0d8c810",
   "metadata": {},
   "source": [
    "## Evaluate the Model on the Validation Dataset\n",
    "\n",
    "Evaluate the model using the validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208446a5-2264-4d42-8503-9e4b562c03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = ProgressBar(message=\"Evaluating Validation Set\")\n",
    "\n",
    "true, predicted = evaluate_dataset(model, validation_dataset)\n",
    "\n",
    "progress_bar.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0105e-0d1e-4bc9-a0a2-5c69921a9cc1",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Generate and display the confusion matrix. The confusion matrix provides a detailed breakdown of how often the model correctly classifies each class and where it makes mistakes, which can help identify any particular classes the model struggles with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c09c9e-c09c-4478-b8ae-e31674b0771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true, predicted)\n",
    "\n",
    "# Display the confusion matrix using a heatmap\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=validation_dataset.class_names).plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd464ae4-c911-4756-8b0d-9c11ab23b3e9",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "Generate a classification report that includes precision, recall, and F1-score for each class. These metrics give a more comprehensive picture of model performance across different classes, helping to understand how well the model performs beyond simple accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3fe60-9a5c-4f57-b372-14794f609ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the classification report as a dictionary\n",
    "report = classification_report(true, predicted, target_names=validation_dataset.class_names, output_dict=True)\n",
    "\n",
    "# Convert to DataFrame for easier visualization\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap='YlGnBu', cbar=False)\n",
    "plt.title(\"Classification Report Heatmap\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arthropod Classifier",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
